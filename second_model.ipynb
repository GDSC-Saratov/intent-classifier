{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "second_model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Download, install and import"
      ],
      "metadata": {
        "id": "pUdSCfeRNXkl"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ChhYGbsNWYo",
        "outputId": "9576df9e-56f1-4a8f-f96d-b6e7aab9c7cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-07-18 16:56:38--  https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.188.48, 172.217.13.80, 142.251.45.16, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.188.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 662903077 (632M) [application/zip]\n",
            "Saving to: ‘multi_cased_L-12_H-768_A-12.zip’\n",
            "\n",
            "multi_cased_L-12_H- 100%[===================>] 632.19M   247MB/s    in 2.6s    \n",
            "\n",
            "2022-07-18 16:56:41 (247 MB/s) - ‘multi_cased_L-12_H-768_A-12.zip’ saved [662903077/662903077]\n",
            "\n",
            "Archive:  multi_cased_L-12_H-768_A-12.zip\n",
            "   creating: multi_cased_L-12_H-768_A-12/\n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.meta  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/vocab.txt  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_model.ckpt.index  \n",
            "  inflating: multi_cased_L-12_H-768_A-12/bert_config.json  \n"
          ]
        }
      ],
      "source": [
        "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
        "!unzip multi_cased_L-12_H-768_A-12.zip\n",
        "!rm multi_cased_L-12_H-768_A-12.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "metadata": {
        "id": "hXICDYuJNef-"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support vars"
      ],
      "metadata": {
        "id": "mePGlKYiNicE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_BERT_DIR = 'multi_cased_L-12_H-768_A-12/'"
      ],
      "metadata": {
        "id": "NEv1LtczNkkj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model (architecture BertModelForSequenceClassification from [transformers/bert](https://github.com/huggingface.transformers/blob/main/src/transformers/models/bert/modeling_bert.py))"
      ],
      "metadata": {
        "id": "RiiJbI3oNtyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classes"
      ],
      "metadata": {
        "id": "XVLkwMnEOIyA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Embeddings(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.word_embeddings = torch.nn.Embedding(119547, 768, padding_idx=0)\n",
        "    self.position_embeddings = torch.nn.Embedding(512, 768)\n",
        "    self.token_type_embeddings = torch.nn.Embedding(2, 768)\n",
        "    self.LayerNorm = torch.nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
        "    self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.word_embeddings(x)\n",
        "    x = self.position_embeddings(x)\n",
        "    x = self.token_type_embeddings(x)\n",
        "    x = self.LayerNorm(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "6Xu-ipl3Nw4Z"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfAttention(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.query = torch.nn.Linear(in_features=768, out_features=768, bias=True)\n",
        "    self.key = torch.nn.Linear(in_features=768, out_features=768, bias=True)\n",
        "    self.value = torch.nn.Linear(in_features=768, out_features=768, bias=True)\n",
        "    self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.query(x)\n",
        "    x = self.key(x)\n",
        "    x = self.value(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "fVRGmhI3NzIo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SelfOutput(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense = torch.nn.Linear(in_features=768, out_features=768, bias=True)\n",
        "    self.LayerNorm = torch.nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
        "    self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.dense(x)\n",
        "    x = self.LayerNorm(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "GjeyQUzMN1VV"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Attention(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.self = SelfAttention()\n",
        "    self.output = SelfOutput()\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.self(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "K0ZsJlJQN3Xv"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Intermediate(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense = torch.nn.Linear(in_features=768, out_features=3072, bias=True)\n",
        "    self.intermediate_act_fn = torch.nn.functional.gelu\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.dense(x)\n",
        "    x = self.intermediate_act_fn(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "fO3ycxxCN5W1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Output(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense = torch.nn.Linear(in_features=3072, out_features=768, bias=True)\n",
        "    self.LayerNorm = torch.nn.LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
        "    self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.dense(x)\n",
        "    x = self.LayerNorm(x)\n",
        "    x = self.dropout(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "Ns7z6NFQN5Mc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.attention = Attention()\n",
        "    self.intermediate = Intermediate()\n",
        "    self.output = Output()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.attention(x)\n",
        "    x = self.intermediate(x)\n",
        "    x = self.output(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "f8VQ_eiLN9aM"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layer = torch.nn.ModuleList(Layer() for i in range(12))\n",
        "  \n",
        "  def forward(self, x):\n",
        "    for i, l in enumerate(self.layer):\n",
        "      x = self.layer[i // 2](x) + l(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "R7j85NXWN_TN"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Pooler(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.dense = torch.nn.Linear(in_features=768, out_features=768, bias=True)\n",
        "    self.activation = torch.nn.Softmax(dim=1) #need define\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.dense(x)\n",
        "    x = self.activation(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "xhT__nbEOBMp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Bert(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.embeddings = Embeddings()\n",
        "    self.encoder = Encoder()\n",
        "    self.pooler = Pooler()\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = self.embeddings(x)\n",
        "    x = self.encoder(x)\n",
        "    x = self.pooler(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "pLnX3YntOEWp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class IntentClassifier(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.bert = Bert()\n",
        "    self.dropout = torch.nn.Dropout(p=0.1, inplace=False)\n",
        "    self.classifier = torch.nn.Linear(in_features=768, out_features=6, bias=True)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.bert(x)\n",
        "    x = self.dropout(x)\n",
        "    x = self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "zsg-c0ksOGkG"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Init"
      ],
      "metadata": {
        "id": "Csg5H4KDONSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = IntentClassifier()"
      ],
      "metadata": {
        "id": "uwWjKK1QOT7O"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HTN6vR6UPPLe",
        "outputId": "1714fe95-c0db-40a3-b4f3-c272ccaa3053"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IntentClassifier(\n",
              "  (bert): Bert(\n",
              "    (embeddings): Embeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): Encoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): Layer(\n",
              "          (attention): Attention(\n",
              "            (self): SelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): SelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): Intermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): Output(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): Pooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Softmax(dim=1)\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}